import threading
from concurrent.futures import ThreadPoolExecutor
from typing import TYPE_CHECKING

from aiocache import Cache
from fastapi import Header, Request

from src.api.core.exceptions import BaseAPIError
from src.schemas.types import ResourceEnum

if TYPE_CHECKING:
    import httpx


_executor: ThreadPoolExecutor | None = None
_executor_lock = threading.Lock()


def get_cache(request: Request) -> Cache:
    """Dependency to inject cache into endpoints."""
    if not hasattr(request.app.state, "cache") or request.app.state.cache is None:
        raise BaseAPIError(message=f"Error loading '{ResourceEnum.CACHE}'")
    return request.app.state.cache


def request_id_header_doc(
    x_request_id: str | None = Header(  # noqa: ARG001
        default=None,
        alias="X-Request-ID",
        description="Optional request ID. If provided, it will be reused; otherwise generated.",
        examples=["my-trace-001"],
    ),
) -> None:
    """
    Dependency to document the X-Request-ID header in OpenAPI.
    By default, it's generated by middleware and not used directly in endpoints.
    """
    return


def get_request_id(request: Request) -> str:
    """Dependency to extract the request ID from the request state."""
    return getattr(request.state, "request_id", "N/A")


def idempotency_key_header(
    idempotency_key: str | None = Header(
        default=None,
        alias="Idempotency-Key",
        description="Optional idempotency key to prevent duplicate processing of requests.",
        examples=["my-idempotency-key"],
    ),
) -> str | None:
    """Dependency to extract the Idempotency-Key header from requests."""
    return idempotency_key


def get_client(request: Request) -> "httpx.AsyncClient":
    """Dependency to inject shared HTTP client into endpoints."""
    if not hasattr(request.app.state, "client") or request.app.state.client is None:
        raise BaseAPIError(message=f"Error loading '{ResourceEnum.DATABASE}'")
    return request.app.state.client


def get_executor(max_workers: int | None = None) -> ThreadPoolExecutor:
    """Return a shared global ThreadPoolExecutor.

    Sharing a single executor across all instances ensures:
    1. Efficient use of system resources (avoids creating a new executor per request).
    2. Proper timeout and cancellation handling with asyncio.
    3. Thread reuse for better performance under concurrent predictions.
    """
    global _executor
    global _executor_lock

    if _executor is None:
        with _executor_lock:
            if _executor is None:
                _executor = ThreadPoolExecutor(
                    max_workers=max_workers,
                    thread_name_prefix="global_threadpool_",
                )

    #  _executor is guaranteed to be initialized
    assert _executor is not None
    return _executor
